产品介绍
===========================

工具链概览
---------------------------

地平线J5芯片工具链（以下简称 工具链）是一套完整的边缘AI算法落地解决方案，可以帮助您把浮点模型量化为定点模型，
并在地平线AI芯片上快速部署自研算法模型。

目前在GPU上训练的模型大部分都是浮点模型，即参数使用的是float类型存储。
地平线BPU架构的AI芯片使用的是int8的计算精度（业内AI芯片的通用精度），能运行定点量化模型。
那么从训练出的浮点精度转为定点模型的过程，我们叫做量化。 
同时模型量化后能够有效减少模型大小，加速深度学习推理的速度，因此也在学术界和工业界的广泛研究和应用。

量化方法为：
  
.. 量化感知训练（即：Quantization Aware Training，量化感知训练方案）：在浮点训练的时候，就先对浮点模型结构进行干预，增加量化误差，使得模型能够感知到量化带来的损失。该方法需要用户在全量训练集上重新训练，能有效的降低量化部署的量化误差。地平线内部有一套闭环的量化训练方案，除此之外一些社区框架也都提供相同的QAT方案，例如pytorch的eager mode方案、pytorch的fx graph方案、tf-lite量化方案等。这种方法一般能够获得较低的精度损失, 但对部署人员的要求也较高。 有关QAT方案的详细信息请阅读 :doc:`QAT量化感知训练方案 <qat_solution>` 章节。

后量化（即：Post-training Quantization，浮点定点转换方案 ）：先训练浮点模型，然后使用校准图片计算量化参数，将浮点模型转为量化模型。该方法简单、快捷，但将浮点模型直接转为量化模型难免会有一些量化损失，地平线浮点转换工具链中提供的后量化工具能做到80%以上的模型量化误差小于1%。 

PTQ方法支持通过公开DL框架获得的浮点模型（Caffe模型或ONNX模型）。 这种方法过程简单，不需要在训练阶段考虑量化问题。

.. 但是在精度上一般要稍微逊色于 QAT。 

有关PTQ方案的详细信息请阅读 :doc:`PTQ浮点定点模型转换方案<ptq_solution>` 章节。

工具链由PTQ模型后量化转换和嵌入式编译等部分组成，其软件逻辑框图如下：

.. image:: ./_static/toolchain_framework.png
  :align: center


其中：

**Runtime SDK** 提供了异构模型的运行库支持，运行库包含arm和x86(暂未提供)两个部分，分别用于在地平线AI芯片平台和X86仿真平台执行异构模型。
有关runtime应用开发请阅读 :doc:`runtime应用开发 <application_development>` 章节。

此外，工具链提供了丰富的开发 **工具**、**示例** 以及内置了大量算法模型的 **模型发布物** 帮助用户上手理解, 并可以提高用户的开发效率。

工具链使用流程
---------------------------

J5 AI芯片工具链的整体使用流程如下图所示：

.. image:: ./_static/toolchain_workflow.png
  :align: center

如上图所示，步骤2中的PTQ方案可完成模型量化。

.. 相对于PTQ方案，QAT方案可以获取更高的模型精度，但上手难度更高。因此，开发者可以根据自身情况以及对模型性能的要求对两种方案进行选择。
.. 下图从实施复杂度、性能、支持的Operator数量、自定义Operator的多寡及精度损失调试几个维度对两种方案进行了比较：

.. .. image:: ./_static/qat_vs_ptq.png
  :align: center

.. 从2套模型处理方案中做出选择后

下一章内容将为您介绍如何搭建开发环境。

