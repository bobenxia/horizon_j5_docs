前言
====

​AI Benchmark示例包提供了Runtime应用开发常见分类、检测、分割和光流估计模型的性能和精度评测示例。
其中性能评测示例包括单帧延迟评测和多线程评测示例，充分利用调用BPU双核的速度评测。
示例包中预置了源码、可执行程序和评测脚本，开发者可以在地平线开发板上进行体验，并基于这些示例直接进行应用开发，降低开发门槛。

发布物说明
==========

​AI Benchmark示例包位于 **horizon_j5_open_explorer** 发布物的 ``ddk/samples/ai_benchmark/`` 路径下，主要包括以下内容：

.. table::

  +----------+----------+----------------------------+
  | **编号** | **名称** | **内容**                   |
  +----------+----------+----------------------------+
  | 1        | code     | 包含示例源代码和编译脚本。 |
  +----------+----------+----------------------------+
  | 2        | j5       | 示例包上板运行环境。       |
  +----------+----------+----------------------------+

示例包结构
-----------------

​示例包结构如下所示：

.. code-block:: bash

  ai_benchmark/code/                    # 示例源码文件夹
  ├── build_ptq_j5.sh
  ├── build_qat_j5.sh
  ├── CMakeLists.txt
  ├── deps_gcc9.3                       # 第三方依赖库
  │   └── aarch64
  ├── include                           # 源码头文件
  │   ├── base
  │   ├── input
  │   ├── method
  │   ├── output
  │   ├── plugin
  │   └── utils
  ├── README.md
  └── src                               # 示例源码
      ├── input
      ├── method
      ├── output
      ├── plugin
      ├── simple_example.cc             # 示例主程序
      └── utils

  ai_benchmark/j5                       # 示例包运行环境
  ├── ptq                               # PTQ方案模型示例
  │   ├── data                          # 模型精度评测数据集
  │   ├── mini_data                     # 模型性能评测数据集
  │   │   ├── cifar10
  │   │   ├── cityscapes
  │   │   ├── coco
  │   │   ├── flyingchairs
  │   │   ├── imagenet
  │   │   └── voc
  │   ├── model                         # PTQ方案nv12模型
  │   ├── README.md
  │   ├── script                        # 执行脚本
  │   │   ├── aarch64                   # 编译产生可执行文件及依赖库
  │   │   ├── classification            # 分类模型示例
  │   │   │   ├── efficientnasnet_m
  │   │   │   ├── efficientnasnet_s
  │   │   │   ├── efficientnet_lite0
  │   │   │   ├── efficientnet_lite1
  │   │   │   ├── efficientnet_lite2
  │   │   │   ├── efficientnet_lite3
  │   │   │   ├── efficientnet_lite4
  │   │   │   ├── googlenet
  │   │   │   ├── mobilenetv1
  │   │   │   ├── mobilenetv2
  │   │   │   ├── resnet18
  │   │   │   └── vargconvnet
  │   │   ├── config                    # 模型推理配置文件
  │   │   │   └── model  
  │   │   ├── detection                 # 检测模型示例
  │   │   │   ├── centernet_resnet101
  │   │   │   ├── ssd_mobilenetv1
  │   │   │   ├── yolov2_darknet19
  │   │   │   ├── yolov3_darknet53
  │   │   │   ├── yolov3_vargdarknet
  │   │   │   └── yolov5x
  │   │   ├── segmentation              # 分割模型示例
  │   │   │   ├── deeplabv3plus_efficientnetb0
  │   │   │   ├── deeplabv3plus_efficientnetm1
  │   │   │   ├── deeplabv3plus_efficientnetm2
  │   │   │   └── fastscnn_efficientnetb0
  │   │   ├── env.sh                    # 基础环境脚本
  │   │   └── README.md
  │   └── tools                         # 精度评测工具
  │       ├── python_tools
  │       └── README.md
  └── qat                               # QAT方案模型示例
      ├── data                          # 模型精度评测数据集
      ├── mini_data                     # 模型性能评测数据集
      ├── model                         # QAT方案nv12模型
      ├── README.md
      ├── script                        # 执行脚本
      │   ├── aarch64                   # 编译产生可执行文件及依赖库
      │   ├── classification            # 分类模型示例
      │   │   ├── mobilenetv1
      │   │   ├── mobilenetv2
      │   │   ├── resnet18
      │   │   ├── resnet50
      │   │   └── vargnetv2
      │   ├── config                    # 模型推理配置文件
      │   │   └── model
      │   ├── detection                 # 检测模型示例
      │   │   ├── fcos_efficientnetb0
      │   │   ├── retinanet
      │   │   └── yolov3_mobilenetv1
      │   ├── opticalflow               # 光流模型示例
      │   │   └── pwcnet_opticalflow
      │   ├── segmentation              # 分割模型示例
      │   │   └── mobilenet_unet
      │   ├── env.sh                    # 基础环境脚本
      │   └── README.md
      └── tools                         # 前处理及精度评测工具
          ├── eval_preprocess
          ├── python_tools
          └── README.md


- **code**：该目录内是评测程序的源码，用来进行模型性能和精度评测。
- **j5**：该目录内提供了已经编译好的应用程序，以及各种评测脚本，用来测试多种模型在地平线BPU上运行的性能和精度等。
- build_ptq_j5.sh：PTQ真机程序一键编译脚本。
- build_qat_j5.sh：QAT真机程序一键编译脚本。
- **deps_gcc9.3**：示例代码所需要的依赖，主要如下所示:

  .. code-block:: bash

    appsdk  gflags  glog  hobotlog  nlohmann  opencv  rapidjson  

示例模型
-----------

AI Benchmark示例包的模型发布物model_zoo位于 ``horizon_j5_open_explorer`` 发布物的
``ddk/samples/ai_toolchain/model_zoo/runtime/`` 路径下，
里面包含常用的分类、检测、分割和光流预测模型，模型的命名规则为： ``{model_name}_{backbone}_{input_size}_{input_type}``。
model_zoo里的模型都是通过PTQ模型转换示例包（即： ``ddk/samples/ai_toolchain/horizon_model_convert_sample/``）编译出来的。
原始模型详细信息可以查看模PTQ模型转换示例包中各模型自路径下的README文档或阅读
`《PTQ模型转换示例手册》文档 <../horizon_model_convert_sample/index.html>`_ 了解更多。

.. table::
  :align: center

  +------------------------------+-------------------------------------------------+
  | PTQMODEL                     | MODEL NAME                                      |
  +==============================+=================================================+
  | centernet_resnet101          | centernet_resnet101_512x512_nv12.bin            |
  +------------------------------+-------------------------------------------------+
  | deeplabv3plus_efficientnetb0 | deeplabv3plus_efficientnetb0_1024x2048_nv12.bin |
  +------------------------------+-------------------------------------------------+
  | deeplabv3plus_efficientnetm1 | deeplabv3plus_efficientnetm1_1024x2048_nv12.bin |
  +------------------------------+-------------------------------------------------+
  | deeplabv3plus_efficientnetm2 | deeplabv3plus_efficientnetm2_1024x2048_nv12.bin |
  +------------------------------+-------------------------------------------------+
  | efficientnasnet_m            | efficientnasnet_m_300x300_nv12.bin              |
  +------------------------------+-------------------------------------------------+
  | efficientnasnet_s            | efficientnasnet_s_280x280_nv12.bin              |
  +------------------------------+-------------------------------------------------+
  | efficientnet_lite0           | efficientnet_lite0_224x224_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | efficientnet_lite1           | efficientnet_lite1_240x240_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | efficientnet_lite2           | efficientnet_lite2_260x260_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | efficientnet_lite3           | efficientnet_lite3_280x280_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | efficientnet_lite4           | efficientnet_lite4_300x300_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | fastscnn_efficientnetb0      | fastscnn_efficientnetb0_1024x2048_nv12.bin      |
  +------------------------------+-------------------------------------------------+
  | googlenet                    | googlenet_224x224_nv12.bin                      |
  +------------------------------+-------------------------------------------------+
  |                              | mobilenetv1_224x224_nv12.bin                    |
  | mobilenetv1                  +-------------------------------------------------+
  |                              | mobilenetv1_128x128_resizer_nv12.bin            |
  +------------------------------+-------------------------------------------------+
  | mobilenetv2                  | mobilenetv2_224x224_nv12.bin                    |
  +------------------------------+-------------------------------------------------+
  | resnet18                     | resnet18_224x224_nv12.bin                       |
  +------------------------------+-------------------------------------------------+
  | ssd_mobilenetv1              | ssd_mobilenetv1_300x300_nv12.bin                |
  +------------------------------+-------------------------------------------------+
  | vargconvnet                  | vargconvnet_224x224_nv12.bin                    |
  +------------------------------+-------------------------------------------------+
  | yolov2_darknet19             | yolov2_darknet19_608x608_nv12.bin               |
  +------------------------------+-------------------------------------------------+
  | yolov3_darknet53             | yolov3_darknet53_416x416_nv12.bin               |
  +------------------------------+-------------------------------------------------+
  | yolov3_vargdarknet           | yolov3_vargdarknet_416x416_nv12.bin             |
  +------------------------------+-------------------------------------------------+
  | yolov5x                      | yolov5x_672x672_nv12.bin                        |
  +------------------------------+-------------------------------------------------+


.. table::
  :align: center

  +---------------------+--------------------------------------------------+
  | QATMODEL            | MODEL NAME                                       |
  +=====================+==================================================+
  | fcos_efficientnetb0 | fcos_efficientnetb0_mscoco/compile/model.hbm     |
  +---------------------+--------------------------------------------------+
  | mobilenet_unet      | dwunet_seg/compile/model.hbm                     |
  +---------------------+--------------------------------------------------+
  | mobilenetv1         | mobilenetv1_cls/compile/model.hbm                |
  +---------------------+--------------------------------------------------+
  | mobilenetv2         | mobilenetv2_cls/compile/model.hbm                |
  +---------------------+--------------------------------------------------+
  | pwcnet_opticalflow  | pwcnet_opticalflow/compile/model.hbm             |
  +---------------------+--------------------------------------------------+
  | resnet18            | resnet18_cls/compile/model.hbm                   |
  +---------------------+--------------------------------------------------+
  | resnet50            | resnet50_cls/compile/model.hbm                   |
  +---------------------+--------------------------------------------------+
  | retinanet           | retinanet_vargnetv2_fpn_mscoco/compile/model.hbm |
  +---------------------+--------------------------------------------------+
  | vargnetv2           | vargnetv2_cls/compile/model.hbm                  |
  +---------------------+--------------------------------------------------+
  | yolov3_mobilenetv1  | yolo_mobilenetv1_det/compile/model.hbm           |
  +---------------------+--------------------------------------------------+



公共数据集
---------------

示例中用到的数据集主要有VOC数据集、COCO数据集、ImageNet数据集、Cityscapes数据集和FlyingChairs数据集。
获取方式如下：

.. code-block:: shell

  VOC：wget -c ftp://vrftp.horizon.ai/Open_Explorer/eval_dataset/VOC.tar.gz
  coco：wget -c ftp://vrftp.horizon.ai/Open_Explorer/eval_dataset/coco.tar.gz
  imagenet：wget -c ftp://vrftp.horizon.ai/Open_Explorer/eval_dataset/imagenet.tar.gz
  cityscapes：wget -c ftp://vrftp.horizon.ai/Open_Explorer/eval_dataset/cityscapes.tar.gz
  flyingchairs：wget -c ftp://vrftp.horizon.ai/Open_Explorer/eval_dataset/flyingchairs.tar.gz

环境构建
========

开发板准备
-----------

1. 拿到开发板后，按照刷机说明升级系统镜像到示例包推荐的系统镜像版本。

2. 确保本地开发机和开发板可以远程连接。

编译
--------

​编译需要当前环境安装好交叉编译工具gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu。
然后执行 **code** 目录下的build_ptq_j5.sh脚本即可一键编译真机环境下的可执行程序，可执行
程序和对应依赖会自动复制到 **j5/ptq/script** 目录下的 **aarch64** 目录下。

.. note::

  需要注意build_ptq_j5.sh脚本里指定的交叉编译工具链的位置是 **/opt** 目录下，用户如果安装在其他位置，可以手动修改下build_ptq_j5.sh。

.. code-block:: shell

  export CC=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-gcc
  export CXX=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-g++

示例使用
========

评测示例
----------

​评测示例脚本主要在 **script** 和 **tools** 目录下。 **script** 是板上运行的评测脚本，包括常见分类、检测、分割和光流预测模型。每个模型下面有三个脚本，分别表示：

- fps.sh实现多线程fps统计（多线程调度，用户可以根据需求自由设置线程数）。
- latency.sh实现单帧延迟性能统计（一个线程，单帧）。
- accuracy.sh用于精度评测。

.. code-block:: shell

  script:

  ├── aarch64                     # 编译产生的可执行文件及依赖库
  │   ├── bin
  │   └── lib
  ├── env.sh                      # 基础配置
  ├── config                      # image_name配置文件
  │   └── model
  │       └── data_name_list
  └── detection                   # 检测模型
      ├── fcos_efficientnetb0     # 在此目录中还有其他模型, 仅以此模型目录为参考
      │   ├── accuracy.sh
      │   ├── fps.sh
      │   ├── latency.sh
      │   ├── workflow_accuracy.json
      │   ├── workflow_fps.json
      │   ├── workflow_latency.json
      ......


**(PTQ)tools** PTQ目录下精度评测需要的脚本。主要包括 **python_tools** 下的精度计算脚本。

.. code-block:: shell

  tools:

  python_tools
    └── accuracy_tools
        ├── cityscapes_metric.py
        ├── cls_eval.py
        ├── coco_metric.py
        ├── config.py
        ├── coco_det_eval.py
        ├── parsing_eval.py
        └── voc_det_eval.py
        └── voc_metric.py

**(QAT)tools** QAT目录下精度评测需要的脚本。主要包括前处理脚本及精度计算脚本。

.. code-block:: shell

  tools:

  tools/
    ├── eval_preprocess
    │     ├── fcos_process.py
    │     ├── imagenet.py
    │     ├── pwcnet_process.py
    │     ├── retinanet_process.py
    │     └── voc.py
    ├── python_tools
    │     └── accuracy_tools
    │         ├── cityscapes_metric.py
    │         ├── cls_eval.py
    │         ├── coco_metric.py
    │         ├── config.py
    │         ├── fcos_eval.py
    │         ├── parsing_eval.py
    │         ├── pwcnet_eval.py
    │         └── retinanet_eval.py
    │         └── voc_metric.py
    │         └── yolov3_eval.py
    └── README.md

.. attention::

  评测前需要执行以下命令，将 **ptq** （ **qat** ） 目录拷贝到开发板上，然后将 **model_zoo/runtime** 拷贝到 **ptq/model** （ **qat/model** ）目录下。

.. code-block:: shell
   
  scp -r ddk/samples/ai_benchmark/j5/ptq root@192.168.1.1:/userdata/ptq/
  scp -r ddk/samples/ai_benchmark/j5/qat root@192.168.1.1:/userdata/qat/
  scp -r ddk/samples/ai_toolchain/model_zoo/runtime root@192.168.1.1:/userdata/ptq/model/



性能评测
---------------

性能评测分为latency和fps两方面。

使用说明
~~~~~~~~

latency:
进入到需要评测的模型目录下 执行 ``sh latency.sh`` 即可测试出单帧延迟。如下图所示：

.. code-block:: shell

  I0419 02:35:07.041095 39124 output_plugin.cc:80]  Infer latency:  [avg:  13.124ms,  max:  13.946ms,  min:  13.048ms], Post process latency: [avg:  3.584ms,  max:  3.650ms,  min:  3.498ms].

.. note::

  - ``infer`` 表示模型推理耗时。
  - ``Post process`` 表示后处理耗时。

fps:
该功能采用多线程并发方式，旨在让模型可以在BPU上达到极致的性能。由于多线程并发及数据采样的原因，在程序启动阶段帧率值会较低，之后帧率会上升并逐渐趋于稳定，帧率的浮动范围控制在0.5%之内。
进入到需要评测的模型目录下执行 ``sh fps.sh`` 即可测试出帧率。如下图所示：

.. code-block:: shell

  I0419 02:35:00.044417 39094 output_plugin.cc:109]  Throughput: 1129.39fps      # 模型帧率

命令行参数说明
~~~~~~~~~~~~~~~

accuracy.sh脚本内容如下：

.. code-block:: shell
  :linenos:
  
  #!/bin/sh

  source ../../env.sh                              # 加载基础配置
  export SHOW_FPS_LOG=1                            # 设置环境变量，打印fps级别log

  ${app} \                                         # 可执行程序，在accuracy.sh脚本中定义
    --config_file=workflow_accuracy.json \         # 加载精度测试workflow配置文件
    --log_level=2                                  # 设置log等级

fps.sh脚本内容如下：

.. code-block:: shell

  #!/bin/sh

  source ../../env.sh
  export SHOW_FPS_LOG=1
  export STAT_CYCLE=100                             # 设置环境变量，FPS 统计周期

  ${app} \
    --config_file=workflow_fps.json \
    --log_level=1

latency.sh脚本内容如下：

.. code-block:: shell

  #!/bin/sh

  source ../../env.sh
  export SHOW_LATENCY_LOG=1                         # 设置环境变量，打印 LATENCY 级别log
  export STAT_CYCLE=50                              # 设置环境变量，LATENCY 统计周期

  ${app} \
    --config_file=workflow_latency.json \
    --log_level=1

配置文件说明
~~~~~~~~~~~~~

以centernet_resnet101模型为例，workflow_accuray.json 配置文件内容如下：

.. code-block::

  {
    "input_config": {
      "input_type": "preprocessed_image",
      "height": 512,
      "width": 512,
      "data_type": 1,
      "image_list_file": "../../../data/coco/coco.lst",
      "need_pre_load": false,
      "limit": 14,
      "need_loop": false,
      "max_cache": 10
    },
    "output_config": {
      "output_type": "eval",
      "eval_enable": true,
      "output_file": "./eval.log",
      "mask_output_file": "./mask.log"
    },
    "workflow": [
      {
        "method_type": "InferMethod",
        "unique_name": "InferMethod",
        "method_config": {
          "core": 0,
          "model_file": "../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin"
        }
      },
      {
        "thread_count": 4,
        "method_type": "PTQCenternetPostProcessMethod",
        "unique_name": "PTQCenternetPostProcessMethod",
        "method_config": {
          "class_num": 80,
          "score_threshold": 0.0,
          "topk": 100,
          "det_name_list": "../../config/model/data_name_list/coco_classes.names"
        }
      }
    ]
  }

workflow_fps.json 配置文件内容如下：

.. code-block::

  {
    "input_config": {
      "input_type": "image",
      "height": 512,
      "width": 512,
      "data_type": 1,
      "image_list_file": "../../../mini_data/coco/coco.lst",
      "need_pre_load": true,
      "limit": 12,
      "need_loop": true,
      "max_cache": 10
    },
    "output_config": {
      "output_type": "image",
      "image_list_enable": true,
      "image_output_dir": "./output_images",
      "in_order": false
    },
    "workflow": [
      {
        "method_type": "InferMethod",
        "unique_name": "InferMethod",
        "method_config": {
          "core": 0,
          "model_file": "../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin"
        }
      },
      {
        "thread_count": 8,
        "method_type": "PTQCenternetPostProcessMethod",
        "unique_name": "PTQCenternetPostProcessMethod",
        "method_config": {
          "class_num": 80,
          "score_threshold": 0.4,
          "topk": 100,
          "det_name_list": "../../config/model/data_name_list/coco_classes.names"
        }
      }
    ]
  }

workflow_latency.json 如下：

.. code-block::

  {
    "input_config": {
      "input_type": "image",
      "height": 512,
      "width": 512,
      "data_type": 1,
      "image_list_file": "../../../mini_data/coco/coco.lst",
      "need_pre_load": true,
      "limit": 2,
      "need_loop": true,
      "max_cache": 10
    },
    "output_config": {
      "output_type": "image",
      "image_list_enable": true,
      "image_output_dir": "./output_images"
    },
    "workflow": [
      {
        "method_type": "InferMethod",
        "unique_name": "InferMethod",
        "method_config": {
          "core": 0,
          "model_file": "../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin"
        }
      },
      {
        "thread_count": 1,
        "method_type": "PTQCenternetPostProcessMethod",
        "unique_name": "PTQCenternetPostProcessMethod",
        "method_config": {
          "class_num": 80,
          "score_threshold": 0.4,
          "topk": 100,
          "det_name_list": "../../config/model/data_name_list/coco_classes.names"
        }
      }
    ]
  }

精度评测
------------

​模型评测分为四步：

1. 数据预处理。
2. 数据挂载。
3. 模型推理。
4. 精度计算。

.. _data_preprocess:

数据预处理
~~~~~~~~~~~~~

​ **PTQ模型数据预处理** 需要在x86仿真环境下运行 ``hb_eval_preprocess`` 工具，对数据集进行预处理。
所谓预处理是指图片数据在送入模型之前的特定处理操作。
比如：图片resize、crop和padding等。
该工具集成于 ``horizon_tc_ui`` 工具中，安装过相应install脚本即可使用，原始数据集经过工具预处理之后，会生成模型对应的前处理二进制文件.bin文件集。
直接运行 ``hb_eval_preprocess --help`` 可以查看工具使用规则。

.. tip::

  关于 ``hb_eval_preprocess`` 工具命令行参数，可键入 ``hb_eval_preprocess -h``， 或查看《HB Mappper工具手册》中的
  `hb_eval_preprocess工具 <../j5_ai_toolchain_tool_guide/hb_mapper/hb_eval_preprocess.html>`_ 一节内容。

下面将详细介绍示例包中每一个模型对应的数据集，以及对应数据集的预处理操作。

- VOC数据集：该数据集主要用于ssd_mobilenetv1检测模型的评测，
  其目录结构如下，示例中主要用到 **Main** 文件下的val.txt文件，
  **JPEGImages** 中的源图片和 **Annotations** 中的标注数据：

  .. code-block:: shell

    .
    └── VOCdevkit                  # 根目录
        └── VOC2012                # 不同年份的数据集，这里只下载了2012的，还有2007等其它年份的
            ├── Annotations        # 存放xml文件，与JPEGImages中的图片一一对应，解释图片的内容等等
            ├── ImageSets          # 该目录下存放的都是txt文件，txt文件中每一行包含一个图片的名称，末尾会加上±1表示正负样本
            │   ├── Action
            │   ├── Layout
            │   ├── Main
            │   └── Segmentation
            ├── JPEGImages         # 存放源图片
            ├── SegmentationClass  # 存放的是图片，语义分割相关
            └── SegmentationObject # 存放的是图片，实例分割相关

对数据集进行预处理：

.. code-block:: bash

  hb_eval_preprocess -m ssd_mobilenetv1 -i VOCdevkit/VOC2012/JPEGImages -v VOCdevkit/VOC2012/ImageSets/Main/val.txt -o ./pre_ssd_mobilenetv1

- COCO数据集：该数据集用于centernet_resnet101、yolov2_darknet19、yolov3_darknet53、yolov3_vargdarknet和yolov5x检测模型的评测，
  其目录如下，示例中主要用到 **annotations** 文件夹下的instances_val2017.json标注文件和 **images** 中的图片：

  .. code-block:: shell

    .
    ├── annotations    # 存放标注数据
    └── images         # 存放源图片

对数据集进行预处理：

.. code-block:: bash

  hb_eval_preprocess -m model_name -i coco/coco_val2017/images -o ./pre_model_name

- ImageNet数据集：该数据集主要用于efficientnasnet_m、efficientnasnet_s、efficientnet_lite0、
  efficientnet_lite1、efficientnet_lite2、efficientnet_lite3、efficientnet_lite4、googlenet、
  mobilenetv1、mobilenetv2、resnet18和vargconvnet分类模型的评测，
  示例中主要用到了标注文件val.txt 和 **val** 目录中的源图片:

  .. code-block:: shell

    .
    ├── val.txt
    └── val

对数据集进行预处理：

.. code-block:: bash

  hb_eval_preprocess -m model_name -i imagenet/val -o ./pre_model_name

- Cityscapes数据集：该数据集用于deeplabv3plus_efficientnetb0、deeplabv3plus_efficientnetm1、deeplabv3plus_efficientnetm2和fastscnn_efficientnetb0模型的评测。示例中主要用到了 **./gtFine/val** 中的标注文件和 **./leftImg8bit/val** 中的源图片。

  .. code-block:: shell

    .
    ├── gtFine
    │   └── val
    │       ├── frankfurt
    │       ├── lindau
    │       └── munster
    └── leftImg8bit
        └── val
            ├── frankfurt
            ├── lindau
            └── munster

对数据集进行预处理：

.. code-block:: bash

  hb_eval_preprocess -m mobilenet_unet -i cityscapes/leftImg8bit/val -o ./pre_mobilenet_unet

示例中精度计算脚本的运行流程是：

- 根据 ``workflow_accurary.json`` 中的 ``image_list_file`` 参数值，去寻找对应数据集的 ``lst`` 文件。
- 根据 ``lst`` 文件存储的前处理文件路径信息，去加载每一个前处理文件，然后进行推理。

所以，生成预处理文件之后，需要生成对应的lst文件，将每一张前处理文件的路径写入到lst文件中，而这个路径与数据集在板端的存放位置有关。
这里我们推荐其存放位置与 ``script`` 文件夹同级目录，如下：

.. code-block:: bash

  |-- ptq
  |   |-- data
  |   |   |-- cityscapes
  |   |   |   -- xxxx.bin             # 前处理好的二进制文件
  |   |   |   -- ....
  |   |   |   -- cityscapes.lst       # lst文件：记录每一个前处理文件的路径
  |   |   |-- coco
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- coco.lst
  |   |   |-- imagenet
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- imagenet.lst
  |   |   |-- voc
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |       -- voc.lst
  |   |-- model
  |   |   |-- ...
  |   |-- script
  |   |   |-- ...

与之对应的lst文件，参考生成方式如下：

.. code-block:: shell

  find ../../../data/coco/fcos -name "*bin*" > ../../../data/coco/coco.lst

这样生成的lst文件中存储的路径为一个相对路径： ``../../../data/`` ，可以与 ``workflow_accurary.json`` 默认的配置路径吻合。
如果需要更改前处理数据集的存放位置，则需要确保对应的 ``lst`` 文件可以被 ``workflow_accurary.json`` 读取到；其次需要确保程序根据 ``lst`` 中的路径信息，能读取到对应的前处理文件。


**QAT模型数据预处理** 需要在x86仿真环境下执行 ``ai_benchmark_j5/j5/qat/tools/eval_preprocess`` 中的前处理脚本。其中QAT光流预测模型新增FlyingChairs数据集：

- FlyingChairs数据集：该数据集用于pwcnet_opticalflow光流模型的评测。示例中主要用到了 **FlyingChairs_release/data** 中的数据和 **./FlyingChairs_train_val.txt** 标注文件。 
  {id}_img1.ppm和{id}_img2.ppm是一个图像对，图像宽度大小是512，高度大小是384；id是从00001至22872的序号，每一图像对的标签是{id}_flow.flo。
  其中 **FlyingChairs_train_val** 文件是用于划分训练集和验证集，标签值为2表示验证集。 
 
  .. code-block:: shell

    .
    ├── FlyingChairs_release
    │   └── data
    │       ├── 00001_img1.ppm
    │       ├── 00001_img2.ppm
    │       └── 00001_flow.ppm
    ├── FlyingChairs_train_val.txt

下面将详细介绍示例包中每一个模型对应数据集的预处理操作。

.. tip::

  使用前请修改脚本中的数据集路径及保存路径使脚本正常运行。

- 分类模型：QAT分类模型使用 ``imagenet.py`` 脚本对 ``ImageNet`` 数据集进行前处理。
    
    .. code-block:: shell

      #!/bin/sh

      python3 imagenet.py --image-path=./standard_imagenet/val/ --save-path=./imagenet_preprocess

    .. note::

      - ``image-path``：ImageNet原始数据集文件。
      - ``save-path``：ImageNet数据集预处理后的文件。

- 分割模型：QAT分割模型不需要前处理，直接输入 ``Cityscapes`` 验证集即可。

- 检测模型：QAT不同检测模型使用不同预处理脚本。fcos_efficientnetb0模型使用 ``fcos_process.py`` 脚本对COCO数据集进行前处理；
  retinanet模型使用 ``retinanet_process.py`` 脚本对COCO数据集进行前处理；yolov3_mobilenetv1模型使用 ``voc.py`` 脚本对VOC数据集进行前处理。
    
    .. code-block:: shell

      #!/bin/sh

      python3 fcos_process.py --image-path=./mscoco/images/val2017/  --label-path=./mscoco/images/annotations/instances_val2017.json --save-path=./fcos_preprocess

    .. note::

      - ``image-path``：COCO原始数据集文件。
      - ``label-path``：COCO数据集标注文件。
      - ``save-path``：COCO数据集预处理后的文件。


    .. code-block:: shell

      #!/bin/sh

      python3 retinanet_process.py --image-path=./mscoco/images/val2017/  --label-path=./mscoco/images/annotations/instances_val2017.json --save-path=./retinanet_preprocess

    .. note::

      - ``image-path``：COCO原始数据集文件。
      - ``label-path``：COCO数据集标注文件。
      - ``save-path``：COCO数据集预处理后的文件。

    .. code-block:: shell

      #!/bin/sh

      python3 voc.py --image-path=./VOCdevkit/VOC2012/JPEGImages/ --save-path=./voc_preprocess

    .. note::

      - ``image-path``：VOC原始数据集文件。
      - ``save-path``：VOC数据集预处理后的文件。


- 光流模型：QAT pwcnet_opticalflow光流模型使用 ``pwcnet_process.py`` 脚本对 ``FlyingChairs`` 数据集进行前处理。

    .. code-block:: shell

      #!/bin/sh

      python3 pwcnet_process.py --input_path=./flyingchairs/FlyingChairs_release/data/  --val_file=./flyingchairs/FlyingChairs_train_val.txt --output_path=./pwcnet_preprocess

    .. note::

      - ``input_path``：FlyingChairs原始数据集文件。
      - ``val_file``：FlyingChairs数据集标签文件。
      - ``output_path``：FlyingChairs数据集预处理后的文件。

生成预处理文件之后，需要生成对应的lst文件，将每一张前处理文件的路径写入到lst文件中，而这个路径与数据集在板端的存放位置有关。 
这里我们推荐其存放位置与 script 文件夹同级目录，如下：

.. code-block:: bash

  |-- qat
  |   |-- data
  |   |   |-- cityscapes
  |   |   |   -- xxxx.bin             # 前处理好的二进制文件
  |   |   |   -- ....
  |   |   |   -- cityscapes.lst       # lst文件：记录每一个前处理文件的路径
  |   |   |-- coco
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- coco.lst
  |   |   |-- imagenet
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- imagenet.lst
  |   |   |-- flyingchairs
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- flyingchairs.lst
  |   |   |-- voc
  |   |   |   -- xxxx.bin
  |   |   |   -- ....
  |   |   |   -- voc.lst
  |   |-- model
  |   |   |-- ...
  |   |-- script
  |   |   |-- ...

生成lst文件的方式如PTQ模型相同。

数据挂载
~~~~~~~~~~~

由于数据集相对较大，不适合直接放在开发板上，可以采用挂载的方式供开发板读取。
服务器PC端：

 .. attention::

  运行此命令需要root权限。

1. 编辑 /etc/exports, 增加一行：
   ``/nfs *(insecure,rw,sync,all_squash,anonuid=1000,anongid=1000,no_subtree_check)``。
   ``/nfs`` 表示本机挂载路径，可替换为用户指定目录
2. 执行命令 ``exportfs -a -r``，使/etc/exports 生效。

板端：

1. 创建需要挂载的目录：``mkdir -p /mnt``。
2. ``mount -t nfs {PC端IP}:/nfs /mnt -o nolock``。

完成将PC端的 **/nfs** 文件夹挂载至板端 **/mnt** 文件夹。按
照此方式，将包含预处理数据的文件夹挂载至板端，并将 **/data** 目录软链接至板端 **/ptq** 目录下，与 **/script** 同级目录。


模型推理
~~~~~~~~

挂载完数据后，登录开发板，执行 **yolo5x/** 目录下的accuracy.sh脚本，如下图所示：

.. code-block:: bash

  root@j5dvb-hynix8G:/userdata/ptq/script/detection/yolo5x# sh accuracy.sh
  ../../aarch64/bin/example --config_file=workflow_accuracy.json --log_level=2
  ...
  I0419 03:14:51.158655 39555 infer_method.cc:107] Predict DoProcess finished.
  I0419 03:14:51.187361 39556 ptq_fcos_post_process_method.cc:123] PTQFcosPostProcessMethod DoProcess finished, predict result: [{"bbox":[-1.518860,71.691170,574.934631,638.294922],"prob":0.750647,"label":21,"class_name":"
  I0118 14:02:43.636204 24782 ptq_fcos_post_process_method.cc:123] PTQFcosPostProcessMethod DoProcess finished, predict result: [{"bbox":[3.432283,164.936249,157.480042,264.276825],"prob":0.544454,"label":62,"class_name":"
  ...

板端程序会在当前目录生成eval.log文件，该文件就是预测结果文件。

精度计算
~~~~~~~~~

对于 **PTQ模型** 其精度计算的脚本在 **python_tools** 目录下，包括：

1. **accuracy_tools** 中的：

  + cls_eval.py是用来计算分类模型的精度；
  + coco_det_eval.py是用来计算使用COCO数据集评测的检测模型的精度；
  + parsing_eval.py是用来计算使用Cityscapes数据集评测的分割模型的精度。   
  + voc_det_eval.py是用来计算使用VOC数据集评测的检测模型的精度。

**PTQ分类模型**

- 使用CIFAR-10数据集和ImageNet数据集的分类模型计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 cls_eval.py --log_file=eval.log --gt_file=val.txt

    .. note::

      - ``log_file``：分类模型的预测结果文件。
      - ``gt_file``：CIFAR-10和ImageNet数据集的标注文件。

**PTQ检测模型**

- 使用COCO数据集的检测模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 det_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json

    .. note::

      - ``eval_result_path``：检测模型的预测结果文件。
      - ``annotation_path``：COCO数据集的标注文件。

- 使用VOC数据集的检测模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 det_eval.py --eval_result_path=eval.log --annotation_path=../Annotations --val_txt_path=../val.txt

    .. note::

      - ``eval_result_path``：检测模型的预测结果文件。
      - ``annotation_path``：VOC数据集的标注文件。
      - ``val_txt_path``：VOC数据集中ImageSets/Main文件夹下的val.txt文件。

**PTQ分割模型**

- 使用Cityscapes数据集的分割模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 parsing_eval.py --log_file=eval.log --gt_path=cityscapes/gtFine/val

    .. note::

      - ``log_file``：分割模型的预测结果文件。
      - ``gt_path``：Cityscapes数据集的标注文件。

对于 **QAT模型** 其精度计算的脚本在 **python_tools** 目录下，包括：

1. **accuracy_tools** 中的:

  + cls_eval.py是用来计算分类模型的精度；
  + retinanet_eval.py是用来计算retinanet检测模型的精度；
  + fcos_eval.py是用来计算fcos检测模型的精度；
  + parsing_eval.py是用来计算使用Cityscapes数据集评测的分割模型的精度；
  + pwcnet_eval.py是用来计算使用FlyingChairs数据集评测的光流模型的精度。
  + yolov3_eval.py是用来计算yolov3检测模型的精度；

**QAT分类模型**

- 使用CIFAR-10数据集和ImageNet数据集的分类模型计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 cls_eval.py --log_file=eval.log --gt_file=val.txt

    .. note::

      - ``log_file``：分类模型的预测结果文件。
      - ``gt_file``：CIFAR-10和ImageNet数据集的标注文件。

**QAT检测模型**

- 使用COCO数据集的检测模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 fcos_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json  --image_path=./mscoco/images/val2017/

    .. note::

      - ``eval_result_path``：fcos检测模型的预测结果文件。
      - ``annotation_path``：COCO数据集的标注文件。
      - ``image_path``：COCO原始数据集。


    .. code-block:: shell

      #!/bin/sh

      python3 retinanet_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json --image_path=./mscoco/images/val2017/

    .. note::

      - ``eval_result_path``：retinanet检测模型的预测结果文件。
      - ``annotation_path``：COCO数据集的标注文件。
      - ``image_path``：COCO原始数据集。

- 使用VOC数据集的检测模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 det_eval.py --eval_result_path=eval.log --annotation_path=../Annotations --val_txt_path=../val.txt --image_height=300  --image_width=300

    .. note::

      - ``eval_result_path``：检测模型的预测结果文件。
      - ``annotation_path``：VOC数据集的标注文件。
      - ``val_txt_path``：VOC数据集中ImageSets/Main文件夹下的val.txt文件。
      - ``image_height``: 图像的高度。
      - ``image_width``: 图像的宽度。

**QAT分割模型**

- 使用Cityscapes数据集的分割模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 parsing_eval.py --log_file=eval.log --gt_path=cityscapes/gtFine/val

    .. note::

      - ``log_file``：分割模型的预测结果文件。
      - ``gt_path``：Cityscapes数据集的标注文件。

**QAT光流模型**

- 使用FlyingChairs数据集的光流模型精度计算方式如下：

    .. code-block:: shell

      #!/bin/sh

      python3 parsing_eval.py --log_file=eval.log --gt_path=./flyingchairs/FlyingChairs_release/data/  --val_file=./flyingchairs/FlyingChairs_train_val.txt

    .. note::

      - ``log_file``：光流模型的预测结果文件。
      - ``val_file``：FlyingChairs数据集标签文件。
      - ``gt_path``：FlyingChairs数据集原始文件。

模型集成
==========

后处理集成主要有2个步骤，以CenterNet模型集成为例：

1. 增加后处理文件ptq_centernet_post_process_method.cc，以及头文件ptq_centernet_post_process_method.h。
2. 增加模型运行脚本及配置文件。

后处理文件添加
---------------

后处理代码文件可直接复用src/method目录下任意后处理文件，主要修改 ``InitFromJsonString`` 函数，以及 ``PostProcess`` 函数即可。

``InitFromJsonString`` 函数主要是读取workflow.json中的后处理相关的参数配置，用户可自定义设置相应的输入参数。
``PostProcess`` 函数主要完成后处理的逻辑。

后处理.cc文件放置于 **ai_benchmark/code/src/method/** 路径下，
.h头文件放置于 **ai_benchmark/code/include/method/** 路径下：

.. code-block:: bash

  +---ai_benchmark
  | +---code                                               # 示例源码
  | | +---include
  | | | +---method                                         # 在此文件夹中添加头文件
  | | | | +---qat_fcos_post_process_method.h
  | | | | +---......
  | | +---src
  | | | +---method                                         # 在此文件夹中添加后处理.cc文件
  | | | | | +---qat_fcos_post_process_method.cc
  | | | | | +---......

增加模型运行脚本及配置文件
-----------------------------

脚本目录结构如下：

.. code-block:: bash

  +---ai_benchmark
  | +---j5/ptq/script                                    # 示例脚本文件夹
  | | +---detection
  | | | +---fcos_efficientnetb0
  | | | | +---accuracy.sh                                # 精度测试脚本
  | | | | +---fps.sh                                     # 性能测试脚本
  | | | | +---latency.sh                                 # 单帧延时示例脚本
  | | | | +---workflow_accuracy.json                     # 精度配置文件
  | | | | +---workflow_fps.json                          # 性能配置文件
  | | | | +---workflow_latency.json                      # 单帧延时配置文件

辅助工具和常用操作
====================

日志
----

​日志主要包括 **示例日志** 和 **DNN日志** 两部分。
其中示例日志是指交付包示例代码中所应用的日志；
DNN日志是指嵌入式runtime库中的日志。
用户根据不同的需求可以设置不同的日志。

示例日志
~~~~~~~~

1. 日志等级。示例日志主要采用glog中的vlog，主要分为四个自定义等级：

  - ``0`` (SYSTEM)，该等级主要用来输出报错信息；
  - ``1`` (REPORT)，该等级在示例代码中主要用来输出性能数据；
  - ``2`` (DETAIL)，该等级在示例代码中主要用来输出系统当前状态信息；
  - ``3`` (DEBUG)，该等级在示例代码中主要用来输出调试信息。
    日志等级设置规则：假设设置了级别为 ``P``，如果发生了一个级别 ``Q`` 比 ``P`` 低，
    则可以启动，否则屏蔽掉；默认DEBUG>DETAIL>REPORT>SYSTEM。

2. 日志等级设置。通过 ``log_level`` 参数来设置日志等级，在运行示例的时候，指定 ``log_level`` 参数来设置等级，
   比如指定 ``log_level=0``，即输出SYSTEM日志；如果指定 ``log_level=3``，
   则输出DEBUG、DETAIL、REPORT和SYSTEM日志。

``dnn`` 日志
~~~~~~~~~~~~~~~~~~~~~~~

关于 ``dnn`` 日志的配置，请阅读 《bpu_sdk_api_doc》文档中的
`配置信息 <../bpu_sdk_api_doc/bpu_sdk_api_doc_cn.html#id20>`_ 一节内容。

算子耗时
--------

概述
~~~~

​对OP性能的统计是通过设置 ``HB_DNN_PROFILER_LOG_PATH`` 环境变量实现的。
对该变量的类型和取值说明如下：

-  ``HB_DNN_PROFILER_LOG_PATH=${path}``：表示OP节点dump的输出路径，程序正常运行完退出后，产生profiler.log文件。

示例
~~~~

以下代码块以ssd_mobilenetv1模型为例，开启8个线程同时RunModel，设置 ``export HB_DNN_PROFILER_LOG_PATH=./``，则统计输出的信息如下：

.. code-block:: c
  :linenos:

  {
    "chip_latency": {
      "BPU_inference_time_cost": {
        "avg_time": 2.3878000000000004,
        "max_time": 3.871,
        "min_time": 1.188
      },
      "CPU_inference_time_cost": {
        "avg_time": 0.34690000000000004,
        "max_time": 0.5260000000000001,
        "min_time": 0.19700000000000004
      }
    },
    "model_latency": {
      "BPU_MobileNet-SSD_subgraph_0": {
        "avg_time": 2.3878000000000004,
        "max_time": 3.871,
        "min_time": 1.188
      },
      "Dequantize_conv11_mbox_conf_1_HzDequantize": {
        "avg_time": 0.1157,
        "max_time": 0.139,
        "min_time": 0.074
      },
      "Dequantize_conv11_mbox_loc_1_HzDequantize": {
        "avg_time": 0.032100000000000004,
        "max_time": 0.044,
        "min_time": 0.017
      },
      "Dequantize_conv13_mbox_conf_1_HzDequantize": {
        "avg_time": 0.063,
        "max_time": 0.093,
        "min_time": 0.034
      },
      "Dequantize_conv13_mbox_loc_1_HzDequantize": {
        "avg_time": 0.0144,
        "max_time": 0.018,
        "min_time": 0.007
      },
      "Dequantize_conv14_2_mbox_conf_1_HzDequantize": {
        "avg_time": 0.0166,
        "max_time": 0.021,
        "min_time": 0.009
      },
      "Dequantize_conv14_2_mbox_loc_1_HzDequantize": {
        "avg_time": 0.006,
        "max_time": 0.008,
        "min_time": 0.002
      },
      "Dequantize_conv15_2_mbox_conf_1_HzDequantize": {
        "avg_time": 0.008400000000000001,
        "max_time": 0.011,
        "min_time": 0.003
      },
      "Dequantize_conv15_2_mbox_loc_1_HzDequantize": {
        "avg_time": 0.0040999999999999995,
        "max_time": 0.006,
        "min_time": 0.001
      },
      "Dequantize_conv16_2_mbox_conf_1_HzDequantize": {
        "avg_time": 0.0052,
        "max_time": 0.008,
        "min_time": 0.002
      },
      "Dequantize_conv16_2_mbox_loc_1_HzDequantize": {
        "avg_time": 0.0033,
        "max_time": 0.005,
        "min_time": 0.001
      },
      "Dequantize_conv17_2_mbox_conf_1_HzDequantize": {
        "avg_time": 0.0033,
        "max_time": 0.005,
        "min_time": 0.001
      },
      "Dequantize_conv17_2_mbox_loc_1_HzDequantize": {
        "avg_time": 0.0033,
        "max_time": 0.005,
        "min_time": 0.0
      },
      "MobileNet-SSD_subgraph_0_output_layout_convert": {
        "avg_time": 0.0715,
        "max_time": 0.163,
        "min_time": 0.046
      }
    },
    "task_latency": {
      "TaskPendingTime": {
        "avg_time": 0.07429999999999999,
        "max_time": 0.099,
        "min_time": 0.018
      },
      "TaskRunningTime": {
        "avg_time": 3.1887,
        "max_time": 4.853,
        "min_time": 1.58
      }
    }
  }
  
以上输出了 model_latency 和 task_latency。其中model_latency中输出了模型每个OP运行所需要的耗时情况，task_latency中输出了模型运行中各个task模块的耗时情况。

.. note::

  程序只有正常退出才会输出profiler.log文件。

dump工具
--------

​通过开启 ``HB_DNN_DUMP_PATH`` 这个环境变量可以dump出模型推理过程中每个节点的输入和输出。
通过dump工具，可以排查模拟器和真机是否存在一致性问题：即相同模型，相同输入，真机和模拟器的输出结果是否完全相同。

常用操作
--------

查看开发板镜像版本
~~~~~~~~~~~~~~~~~~~

​使用 ``uname -a`` 命令可以查看到系统的版本，执行命令后如下图所示，

.. code-block:: shell

  root@j5dvb-hynix8G:/userdata# uname -a
  Linux j5dvb-hynix8G 4.14.74-00695-gb3d914ab7-dirty #1 SMP Sun Aug 15 14:41:13 CST 2021 aarch64 GNU/Linux

.. note::

   - ``SMP`` 代表该系统支持对称多处理（Symmetrical Multi-Processing）。
   - ``PREEMPT`` 代表系统支持抢占式内核。
   - ``Oct 23 10:47:39 CST 2020`` 代表系统镜像发布时间。
   - ``aarch64`` 代表系统支持平台为aarch64平台。

查看系统日志
~~~~~~~~~~~~

​使用 ``dmesg`` 命令可以查看系统日志，如下图所示：

.. code-block:: shell

  root@j5dvb-hynix8G:/userdata# dmesg
  [    0.000000] Booting Linux on physical CPU 0x0
  [    0.000000] Linux version 4.14.74 (jenkins@sysgbj8) (gcc version 6.5.0 (Linaro GCC 6.5-2018.12)) #2 SMP PREEMPT Fri Oct 23 10:47:39 CST 2020
  [    0.000000] Boot CPU: AArch64 Processor [410fd034]
  [    0.000000] Machine model: Hobot J5 SOC MP DVB
  [    0.000000] earlycon: hobot0 at MMIO 0x00000000a5000000 (options '')
  [    0.000000] bootconsole [hobot0] enabled
  ...

在上板运行程序的时候，假如发生系统错误（比如程序被killed或者mem分配失败等），执行 ``dmesg`` 后可以看到系统发生错误的具体原因。

查看BPU使用率
~~~~~~~~~~~~~~

​使用 ``hrut_somstatus`` 命令可以查看当前开发板的BPU使用率，执行命令后如下图所示：

.. code-block::

  =====================1=====================
  temperature-->
        ddr_cv_cam-thermal : 35.7 (C)
        soc-thermal : 35.6 (C)
        bpu0_r-thermal : 34.3 (C)
        ddr0_sram : 35.3 (C)
        bpu0_b_top : 34.1 (C)
        bpu0_video : 35.1 (C)
        ddr0_video : 35.2 (C)
        peri     : 35.1 (C)
        bpu1_cpu-thermal : 34.7 (C)
        bpu1_sram : 35.3 (C)
        bpu1_top : 34.4 (C)
        bpu1_left : 34.4 (C)
        bpu0_cam_cv : 35.2 (C)
        ddr1_cam : 35.7 (C)
        cpu-thermal : 35.0 (C)
        cpu_t-thermal : 35.0 (C)
  cpu frequency-->
                min       cur     max
          cpu0: 24000     1200000 1200000
          cpu1: 24000     1200000 1200000
          cpu2: 24000     1200000 1200000
          cpu3: 24000     1200000 1200000
          cpu4: 24000     1200000 1200000
          cpu5: 24000     1200000 1200000
          cpu6: 24000     1200000 1200000
          cpu7: 24000     1200000 1200000
  bpu status information---->
              min        cur             max             ratio
          bpu0: 200000000 1200000000      1200000000      0
          bpu1: 200000000 1200000000      1200000000      0

